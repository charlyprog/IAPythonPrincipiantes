"""
app_refactorizado.py - Aplicaci√≥n Principal del Chatbot RAG
============================================================

Este es el archivo principal que integra todos los m√≥dulos y
crea la interfaz de usuario con Gradio.

ARQUITECTURA MODULAR:
- config.py: Configuraci√≥n centralizada
- database_manager.py: Gesti√≥n de ChromaDB
- document_processor.py: Procesamiento de documentos
- rag_chain.py: Cadena RAG completa
- app_refactorizado.py: Integraci√≥n e interfaz (ESTE ARCHIVO)

¬øPOR QU√â MODULARIZAR?
- C√≥digo m√°s organizado y f√°cil de entender
- Cada m√≥dulo tiene una responsabilidad clara
- Facilita el mantenimiento y pruebas
- Permite reutilizar componentes en otros proyectos

Autor: Clase 24 - IA Python para Principiantes
Fecha: 2025
"""

import gradio as gr
from database_manager import DatabaseManager
from document_processor import DocumentProcessor
from rag_chain import RAGChain
from config import (
    APP_TITLE,
    APP_DESCRIPTION,
    CHAT_HEIGHT,
    ALLOWED_FILE_TYPES,
    UI_THEME,
    MSG_STARTING_UI
)

# ==============================================================================
# 1. INICIALIZACI√ìN DE COMPONENTES GLOBALES
# ==============================================================================

print("=" * 70)
print("üöÄ INICIANDO CHATBOT RAG - Versi√≥n Modular")
print("=" * 70)

# Inicializar el gestor de base de datos
# Este componente maneja ChromaDB y los embeddings
print("\nüì¶ Inicializando componentes...")
db_manager = DatabaseManager()

# Inicializar el procesador de documentos
# Este componente carga y procesa archivos
doc_processor = DocumentProcessor()

# Inicializar la cadena RAG
# Este componente conecta retriever + LLM
rag_chain = RAGChain(db_manager)

print("‚úÖ Todos los componentes inicializados correctamente\n")

# ==============================================================================
# 2. FUNCIONES DE LA INTERFAZ DE USUARIO
# ==============================================================================

def handle_file_upload(file_list):
    """
    Maneja la carga de archivos desde la interfaz de Gradio.
    
    Esta funci√≥n:
    1. Extrae las rutas de los archivos subidos
    2. Procesa los archivos (carga y divide en chunks)
    3. A√±ade los fragmentos a la base de datos
    4. Actualiza las estad√≠sticas
    
    Args:
        file_list: Lista de archivos subidos por Gradio
                   Cada elemento tiene un atributo .name con la ruta
                   
    Returns:
        tuple: (mensaje_estado, estad√≠sticas_actualizadas)
        
    Nota para estudiantes:
        Esta funci√≥n es el "pegamento" entre la interfaz de Gradio
        y nuestra l√≥gica de negocio en los m√≥dulos.
    """
    # Validar que se hayan subido archivos
    if not file_list:
        stats = db_manager.get_stats()
        return "‚ö†Ô∏è Por favor, selecciona al menos un archivo.", stats['message']
    
    try:
        # Extraer las rutas de los archivos
        file_paths = [file_obj.name for file_obj in file_list]
        
        print(f"\n{'='*70}")
        print(f"üì§ CARGA DE ARCHIVOS INICIADA")
        print(f"{'='*70}")
        
        # Paso 1: Procesar los archivos (cargar y dividir)
        result = doc_processor.process_files(file_paths)
        
        # Si el procesamiento fall√≥, retornar mensaje de error
        if not result['success']:
            stats = db_manager.get_stats()
            return result['message'], stats['message']
        
        # Paso 2: A√±adir los fragmentos a la base de datos
        splits = result['splits']
        db_manager.add_documents(splits)
        
        # Paso 3: Actualizar estad√≠sticas
        stats = db_manager.get_stats()
        
        # Crear mensaje de √©xito detallado
        success_message = (
            f"‚úÖ ¬°√âxito!\n\n"
            f"üìÑ Archivos procesados: {len(file_paths)}\n"
            f"üìä Fragmentos creados: {result['split_count']}\n"
            f"üíæ Total en base de datos: {stats['count']:,}"
        )
        
        if result['failed_files']:
            success_message += f"\n\n‚ö†Ô∏è Archivos con error: {len(result['failed_files'])}"
        
        print(f"\n{'='*70}")
        print(f"‚úÖ CARGA COMPLETADA")
        print(f"{'='*70}\n")
        
        return success_message, stats['message']
        
    except Exception as e:
        print(f"\n‚ùå Error en handle_file_upload: {e}\n")
        stats = db_manager.get_stats()
        return f"‚ùå Error al procesar archivos: {str(e)}", stats['message']


def handle_chat_message(message, chat_history):
    """
    Maneja los mensajes del chat.
    
    Esta funci√≥n:
    1. Recibe el mensaje del usuario
    2. Usa la cadena RAG para generar una respuesta
    3. Actualiza el historial del chat
    
    Args:
        message (str): Mensaje/pregunta del usuario
        chat_history (list): Historial de mensajes [(user, bot), ...]
        
    Returns:
        tuple: ("", chat_history_actualizado)
               Retornamos "" para limpiar el input
               
    Nota para estudiantes:
        Gradio maneja autom√°ticamente el historial del chat.
        Solo necesitamos agregarlo a la lista.
    """
    # Validar que el mensaje no est√© vac√≠o
    if not message or message.strip() == "":
        return "", chat_history
    
    try:
        print(f"\n{'='*70}")
        print(f"üí¨ NUEVA PREGUNTA")
        print(f"{'='*70}")
        print(f"Usuario: {message[:100]}...")
        
        # Generar respuesta usando la cadena RAG
        response = rag_chain.query(message)
        
        # Agregar al historial del chat
        # Formato de Gradio: (mensaje_usuario, respuesta_bot)
        chat_history.append((message, response))
        
        print(f"Bot: {response[:100]}...")
        print(f"{'='*70}\n")
        
        # Retornar input vac√≠o y historial actualizado
        return "", chat_history
        
    except Exception as e:
        print(f"\n‚ùå Error en handle_chat_message: {e}\n")
        # En caso de error, mostrar mensaje al usuario
        error_response = (
            f"üòî Lo siento, ocurri√≥ un error al procesar tu pregunta.\n\n"
            f"Error: {str(e)}\n\n"
            f"Por favor, intenta de nuevo o contacta al administrador."
        )
        chat_history.append((message, error_response))
        return "", chat_history


def handle_clear_database():
    """
    Maneja la limpieza de la base de datos.
    
    Esta funci√≥n:
    1. Elimina todos los documentos de ChromaDB
    2. Actualiza las estad√≠sticas
    
    Returns:
        tuple: (mensaje_resultado, estad√≠sticas_actualizadas)
        
    Advertencia:
        Esta operaci√≥n no se puede deshacer.
        Todos los documentos ser√°n eliminados permanentemente.
    """
    try:
        print(f"\n{'='*70}")
        print(f"üóëÔ∏è LIMPIEZA DE BASE DE DATOS")
        print(f"{'='*70}")
        
        # Limpiar la base de datos
        result = db_manager.clear_all_documents()
        
        # Actualizar estad√≠sticas
        stats = db_manager.get_stats()
        
        print(f"{result['message']}")
        print(f"{'='*70}\n")
        
        return result['message'], stats['message']
        
    except Exception as e:
        print(f"\n‚ùå Error en handle_clear_database: {e}\n")
        stats = db_manager.get_stats()
        return f"‚ùå Error al limpiar la base de datos: {str(e)}", stats['message']


def handle_refresh_stats():
    """
    Actualiza las estad√≠sticas de la base de datos.
    
    Returns:
        str: Mensaje con las estad√≠sticas actualizadas
    """
    stats = db_manager.get_stats()
    return stats['message']


# ==============================================================================
# 3. CONSTRUCCI√ìN DE LA INTERFAZ DE GRADIO
# ==============================================================================

print(MSG_STARTING_UI)

# Crear la interfaz usando Blocks (m√°s flexible que Interface)
with gr.Blocks(theme=gr.themes.Soft(), title=APP_TITLE) as demo:
    
    # === ENCABEZADO COMPACTO ===
    gr.Markdown(f"# {APP_TITLE}\n{APP_DESCRIPTION}")
    
    # === PESTA√ëA 1: CHATBOT ===
    with gr.Tab("üí¨ Chatbot"):
        # Instrucciones colapsables para ahorrar espacio
        with gr.Accordion("‚ÑπÔ∏è ¬øC√≥mo usar el chatbot?", open=False):
            gr.Markdown("""
            1. Primero, carga tus documentos en la pesta√±a "üìö Base de Conocimiento"
            2. Luego, haz preguntas sobre el contenido de esos documentos
            3. El chatbot responder√° bas√°ndose SOLO en la informaci√≥n de tus archivos
            """)
        
        # Componente de chat
        chatbot = gr.Chatbot(
            label="Conversaci√≥n",
            height=CHAT_HEIGHT,
            show_label=True
        )
        
        # Input para mensajes
        msg_input = gr.Textbox(
            label="Escribe tu pregunta aqu√≠...",
            placeholder="Ejemplo: ¬øCu√°l es el tema principal del documento?",
            lines=1,
            max_lines=3
        )
        
        # Botones de acci√≥n
        with gr.Row():
            submit_btn = gr.Button("üì§ Enviar", variant="primary")
            clear_chat_btn = gr.ClearButton(
                [msg_input, chatbot],
                value="üóëÔ∏è Limpiar Chat"
            )
        
        # Conectar eventos
        # Enviar mensaje al presionar Enter o bot√≥n
        msg_input.submit(
            handle_chat_message,
            inputs=[msg_input, chatbot],
            outputs=[msg_input, chatbot]
        )
        submit_btn.click(
            handle_chat_message,
            inputs=[msg_input, chatbot],
            outputs=[msg_input, chatbot]
        )
    
    # === PESTA√ëA 2: GESTI√ìN DE DOCUMENTOS ===
    with gr.Tab("üìö Base de Conocimiento"):
        
        # === SECCI√ìN: ESTAD√çSTICAS ===
        with gr.Row():
            stats_display = gr.Markdown(
                value=db_manager.get_stats()['message']
            )
            refresh_btn = gr.Button("üîÑ Actualizar", size="sm", scale=0)
        
        # === SECCI√ìN: CARGAR ARCHIVOS ===
        with gr.Group():
            gr.Markdown("### üì§ Cargar Documentos")
            file_upload = gr.File(
                label="Archivos (.txt, .pdf)",
                file_count="multiple",
                file_types=ALLOWED_FILE_TYPES,
                interactive=True
            )
            upload_btn = gr.Button("üì• Analizar y Cargar", variant="primary")
            upload_status = gr.Textbox(
                label="Resultado",
                interactive=False,
                lines=3
            )
        
        # === SECCI√ìN: ZONA DE PELIGRO ===
        with gr.Group():
            gr.Markdown("### ‚ö†Ô∏è Limpiar Base de Datos")
            clear_db_btn = gr.Button(
                "üóëÔ∏è Eliminar Todos los Documentos",
                variant="stop"
            )
            clear_status = gr.Textbox(
                label="Resultado",
                interactive=False,
                lines=2
            )
        
        # Conectar eventos de esta pesta√±a
        upload_btn.click(
            handle_file_upload,
            inputs=[file_upload],
            outputs=[upload_status, stats_display]
        )
        
        refresh_btn.click(
            handle_refresh_stats,
            inputs=[],
            outputs=[stats_display]
        )
        
        clear_db_btn.click(
            handle_clear_database,
            inputs=[],
            outputs=[clear_status, stats_display]
        )
    
    # === PESTA√ëA 3: INFORMACI√ìN ===
    with gr.Tab("‚ÑπÔ∏è Informaci√≥n"):
        gr.Markdown("# üìö Chatbot RAG - Informaci√≥n del Proyecto")
        
        # Acordeones colapsables para informaci√≥n compacta
        with gr.Accordion("¬øQu√© es RAG?", open=True):
            gr.Markdown("""
            **RAG** = *Retrieval Augmented Generation* (Generaci√≥n Aumentada por Recuperaci√≥n)
            
            Combina:
            - **Recuperaci√≥n**: Busca informaci√≥n relevante en documentos
            - **Generaci√≥n**: Usa un LLM para respuestas basadas en esa informaci√≥n
            """)
        
        with gr.Accordion("¬øC√≥mo funciona?", open=False):
            gr.Markdown("""
            1. üìÑ Cargas documentos (PDF/TXT)
            2. ‚úÇÔ∏è Se dividen en fragmentos (chunks)
            3. üî¢ Se convierten en vectores (embeddings)
            4. üíæ Se guardan en ChromaDB
            5. üí¨ Haces una pregunta
            6. üîç Se buscan fragmentos relevantes
            7. ü§ñ El LLM genera respuesta con ese contexto
            """)
        
        with gr.Accordion("Tecnolog√≠as", open=False):
            gr.Markdown("""
            - **LangChain**: Framework para LLMs
            - **Google Gemini**: Modelo de lenguaje
            - **ChromaDB**: Base de datos vectorial
            - **Sentence Transformers**: Embeddings
            - **Gradio**: Interfaz web
            """)
        
        with gr.Accordion("Arquitectura Modular", open=False):
            gr.Markdown("""
            - `config.py` ‚Üí Configuraci√≥n
            - `database_manager.py` ‚Üí ChromaDB
            - `document_processor.py` ‚Üí Procesamiento
            - `rag_chain.py` ‚Üí L√≥gica RAG
            - `app_refactorizado.py` ‚Üí Interfaz
            """)
        
        with gr.Accordion("Ventajas de RAG", open=False):
            gr.Markdown("""
            ‚úÖ Respuestas basadas en TUS documentos  
            ‚úÖ Reduce "alucinaciones" del LLM  
            ‚úÖ Conocimiento actualizable sin reentrenar  
            ‚úÖ Transparente y verificable
            """)
        
        with gr.Accordion("Recursos de Aprendizaje", open=False):
            gr.Markdown("""
            - [LangChain](https://python.langchain.com/)
            - [ChromaDB](https://docs.trychroma.com/)
            - [Gradio](https://www.gradio.app/)
            """)
        
        gr.Markdown("---")
        gr.Markdown("üí° **Clase 24 - IA Python para Principiantes**")

# ==============================================================================
# 4. LANZAR LA APLICACI√ìN
# ==============================================================================

if __name__ == "__main__":
    print("\n" + "="*70)
    print("üéâ APLICACI√ìN LISTA")
    print("="*70)
    print("\nüåê Lanzando servidor web...")
    print("üí° Presiona Ctrl+C para detener el servidor\n")
    
    # Lanzar la interfaz de Gradio
    demo.launch(
        share=True,  # Crear enlace p√∫blico temporal (opcional)
        # server_name="0.0.0.0",  # Descomentar para acceso desde otras m√°quinas
        # server_port=7860,       # Puerto personalizado
    )

# ==============================================================================
# NOTAS PARA ESTUDIANTES
# ==============================================================================
"""
üìö CONCEPTOS IMPORTANTES:

1. ARQUITECTURA MODULAR:
   - Separaci√≥n de responsabilidades
   - Cada m√≥dulo tiene un prop√≥sito claro
   - Facilita mantenimiento y testing
   
2. INTERFAZ DE USUARIO CON GRADIO:
   - gr.Blocks: Construcci√≥n flexible de UI
   - gr.Tab: Organizaci√≥n en pesta√±as
   - Componentes reactivos: actualizan autom√°ticamente
   
3. MANEJO DE EVENTOS:
   - .click(), .submit(): Conectan acciones con funciones
   - inputs/outputs: Definen el flujo de datos
   - return multiple values: Actualizar varios componentes
   
4. GESTI√ìN DE ESTADO:
   - Variables globales para componentes persistentes
   - chat_history: Gradio lo maneja autom√°ticamente
   - Estad√≠sticas: Se actualizan reactivamente

üí° EJERCICIOS SUGERIDOS:
   1. Agrega una pesta√±a para mostrar las fuentes de cada respuesta
   2. Implementa un bot√≥n de "exportar conversaci√≥n"
   3. A√±ade estad√≠sticas visuales con gr.Plot
   
‚ö†Ô∏è PARA PRODUCCI√ìN:
   - Agregar autenticaci√≥n de usuarios
   - Implementar rate limiting
   - Usar una base de datos persistente real
   - Agregar logging y monitoreo
   - Validaci√≥n robusta de inputs
"""
